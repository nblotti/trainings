{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import os"
   ],
   "id": "e13de140e0e2ec95"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T15:09:38.789459Z",
     "start_time": "2024-07-04T15:09:38.786987Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# SECURE THIS KEY!\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://azqoreai.openai.azure.com/\"\n",
    "os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"] = \"gpt-35-turbo-16k_azqore_ai\"\n",
    "os.environ[\"AZURE_OPENAI_API_VERSION\"] = \"2024-02-01\""
   ],
   "id": "f88ec88033e14379",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T15:09:46.814956Z",
     "start_time": "2024-07-04T15:09:40.830043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "model = AzureChatOpenAI(\n",
    "    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"],\n",
    ")\n",
    "\n",
    "\n",
    "code_prompt = PromptTemplate(\n",
    "    template=\"Write a very short {language} function that will {task}\"\n",
    ")\n",
    "\n",
    "output_parser= StrOutputParser()\n",
    "\n",
    "chain = code_prompt | model | output_parser\n",
    "chain.invoke({\n",
    "    \"language\": \"python\",\n",
    "    \"task\": \"return a list of numbers\"\n",
    "})\n"
   ],
   "id": "79a64830eabe230b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here is a simple Python function that returns a list of numbers:\\n\\n```python\\ndef get_numbers():\\n    numbers = [1, 2, 3, 4, 5]\\n    return numbers\\n```\\n\\nYou can modify the `numbers` list to include any sequence of numbers you want.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T15:19:43.349507Z",
     "start_time": "2024-07-04T15:19:43.343607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "schema_representation = code_prompt.schema()\n",
    "print(schema_representation)"
   ],
   "id": "a4e5edb5ff90eef3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'PromptTemplate', 'description': 'Prompt template for a language model.\\n\\nA prompt template consists of a string template. It accepts a set of parameters\\nfrom the user that can be used to generate a prompt for a language model.\\n\\nThe template can be formatted using either f-strings (default) or jinja2 syntax.\\n\\n*Security warning*: Prefer using `template_format=\"f-string\"` instead of\\n    `template_format=\"jinja2\"`, or make sure to NEVER accept jinja2 templates\\n    from untrusted sources as they may lead to arbitrary Python code execution.\\n\\n    As of LangChain 0.0.329, Jinja2 templates will be rendered using\\n    Jinja2\\'s SandboxedEnvironment by default. This sand-boxing should\\n    be treated as a best-effort approach rather than a guarantee of security,\\n    as it is an opt-out rather than opt-in approach.\\n\\n    Despite the sand-boxing, we recommend to never use jinja2 templates\\n    from untrusted sources.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        from langchain_core.prompts import PromptTemplate\\n\\n        # Instantiation using from_template (recommended)\\n        prompt = PromptTemplate.from_template(\"Say {foo}\")\\n        prompt.format(foo=\"bar\")\\n\\n        # Instantiation using initializer\\n        prompt = PromptTemplate(template=\"Say {foo}\")', 'type': 'object', 'properties': {'name': {'title': 'Name', 'type': 'string'}, 'input_variables': {'title': 'Input Variables', 'type': 'array', 'items': {'type': 'string'}}, 'input_types': {'title': 'Input Types', 'type': 'object'}, 'output_parser': {'$ref': '#/definitions/BaseOutputParser'}, 'partial_variables': {'title': 'Partial Variables', 'type': 'object'}, 'metadata': {'title': 'Metadata', 'type': 'object'}, 'tags': {'title': 'Tags', 'type': 'array', 'items': {'type': 'string'}}, 'template': {'title': 'Template', 'type': 'string'}, 'template_format': {'title': 'Template Format', 'default': 'f-string', 'enum': ['f-string', 'mustache', 'jinja2'], 'type': 'string'}, 'validate_template': {'title': 'Validate Template', 'default': False, 'type': 'boolean'}}, 'required': ['input_variables', 'template'], 'definitions': {'BaseOutputParser': {'title': 'BaseOutputParser', 'description': 'Base class to parse the output of an LLM call.\\n\\nOutput parsers help structure language model responses.\\n\\nExample:\\n    .. code-block:: python\\n\\n        class BooleanOutputParser(BaseOutputParser[bool]):\\n            true_val: str = \"YES\"\\n            false_val: str = \"NO\"\\n\\n            def parse(self, text: str) -> bool:\\n                cleaned_text = text.strip().upper()\\n                if cleaned_text not in (self.true_val.upper(), self.false_val.upper()):\\n                    raise OutputParserException(\\n                        f\"BooleanOutputParser expected output value to either be \"\\n                        f\"{self.true_val} or {self.false_val} (case-insensitive). \"\\n                        f\"Received {cleaned_text}.\"\\n                    )\\n                return cleaned_text == self.true_val.upper()\\n\\n            @property\\n            def _type(self) -> str:\\n                return \"boolean_output_parser\"', 'type': 'object', 'properties': {'name': {'title': 'Name', 'type': 'string'}}}}}\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4e10dec4fe397270"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
